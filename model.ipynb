{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HAMZA\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import Utils as utils\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from sklearn import ensemble\n",
    "from sklearn import multioutput\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import StandardScaler,RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_parquet(\"train_final.parquet\")\n",
    "test = pd.read_parquet(\"test_final.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_Target_spareted(dataframe):\n",
    "    new_spareted_cabin = dataframe[\"target\"].str.split(pat = \",\", expand = True)\n",
    "    \n",
    "    dataframe.drop(\"target\", axis=1, inplace=True)\n",
    "    \n",
    "    new_spareted_cabin.rename(columns={0 : 'first_menu',\n",
    "                                       1 : 'second_menu',\n",
    "                                       2 : 'third_menu'}, inplace=True)\n",
    "    \n",
    "    return pd.concat([dataframe, new_spareted_cabin], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = do_Target_spareted(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "transformed_data_first = lb.fit_transform(train_df[\"first_menu\"])\n",
    "transformed_data_second = lb.fit_transform(train_df[\"second_menu\"])\n",
    "transformed_data_third = lb.fit_transform(train_df[\"third_menu\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data_second = [np.insert(row, 4, 0) for row in transformed_data_second]\n",
    "transformed_data_third = [np.insert(row, 2, 0) for row in transformed_data_third]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data_list = [row.tolist() for row in transformed_data_first]\n",
    "\n",
    "# Listeyi Pandas Serisi'ne dönüştürme\n",
    "transformed_data_series = pd.Series(transformed_data_list)\n",
    "\n",
    "\n",
    "transformed_data_list_second = [row.tolist() for row in transformed_data_second]\n",
    "\n",
    "# Listeyi Pandas Serisi'ne dönüştürme\n",
    "transformed_data_series_second = pd.Series(transformed_data_list_second)\n",
    "\n",
    "\n",
    "transformed_data_list_third = [row.tolist() for row in transformed_data_third]\n",
    "\n",
    "# Listeyi Pandas Serisi'ne dönüştürme\n",
    "transformed_data_series_third = pd.Series(transformed_data_list_third)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"first_menu\"] = transformed_data_series\n",
    "train_df[\"second_menu\"] = transformed_data_series_second\n",
    "train_df[\"third_menu\"] = transformed_data_series_third"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['target'] = train_df.apply(lambda row: [1 if any(x) else 0 for x in zip(*row[['first_menu', 'second_menu', 'third_menu']])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop([\"first_menu\",\"second_menu\",\"third_menu\"], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop(\"target\", axis=1)\n",
    "y = train_df[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_dizi = y.to_numpy()\n",
    "numpy_dizi = [np.array(row) for row in numpy_dizi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['carrier'] = train_df['carrier'].apply(lambda x: 'VODAFONE' if 'VODAFONE' in x else x)\n",
    "train_df['carrier'] = train_df['carrier'].apply(lambda x: 'VODAFONE' if 'VF' in x else x)\n",
    "train_df['carrier'] = train_df['carrier'].apply(lambda x: 'TURKCELL' if 'LIFECELL' in x else x)\n",
    "train_df['carrier'] = train_df['carrier'].apply(lambda x: 'TURK_TELEKOM' if 'TURK TELEKO' in x else x)\n",
    "train_df['carrier'] = train_df['carrier'].apply(lambda x: 'TURK_TELEKOM' if 'TÜRK TELEKO' in x else x)\n",
    "train_df['carrier'] = train_df['carrier'].apply(lambda x: 'TURK_TELEKOM' if 'TURKTELEKOM' in x else x)\n",
    "train_df['carrier'] = train_df['carrier'].str.replace('^KCELL ', 'AKCELL', regex=True) \n",
    "\n",
    "yurtdisi = ['ALMADAR','AIRTEL','AZERCELL','BAKCELL','O2','BEE','A1 ','3_AT','IRANCELL',\n",
    "            'AYYILDIZ','BH','NL','ORANGE','MOLDCELL','ZAIN','YETTEL','VERIZONE','TELEKOM',\n",
    "            'TELENOR','TELE2','TELIA','MAGTI','STC','BOUYGUES','HORMUUD','JIO','LIDL','KSA',\n",
    "            'FREEDOM','BUDGET','XFINITY','CHINA_TELECOM','MTN','1&1','BASE','CLARO','GEOCELL',\n",
    "            'MEGAFONE','GSMOBILE','ETISALAT','TIM','MAXIS','PROXIMUS', 'SUNRISE', 'WINDTRE', \n",
    "            'VODACOM', 'LYCAMOBILE','LIBYANA','TIGO', 'ASIACELL', 'SFR','CUBACELL','AKCELL','SALT','T-MOBILE'] \n",
    "sirket = ['TURKCELL','BIMCELL','AVEA','VODAFONE','TURK_TELEKOM','TEKNOSA','PTTCELL','KKTCELL']\n",
    "\n",
    "birlesim = yurtdisi+sirket\n",
    "\n",
    "for anahtarKelime in birlesim:\n",
    "    train_df['carrier'] = train_df['carrier'].apply(lambda x: anahtarKelime if anahtarKelime in x else x)\n",
    "    \n",
    "unknown1 = ['HAYAT','FENER','TRABZON','61','UNKNOWN',' ','nknown']\n",
    "for anahtarKelime in unknown1:\n",
    "    train_df['carrier'] = train_df['carrier'].apply(lambda x: 'UNKNOWN' if anahtarKelime in x else x)\n",
    "    \n",
    "b=train_df['carrier'].unique()\n",
    "\n",
    "unknown = [row for row in b if row not in birlesim]\n",
    "train_df['carrier'] = train_df['carrier'].apply(lambda x: 'UNKNOWN' if x in unknown else x if x not in unknown else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal = ['carrier', 'devicebrand'] \n",
    "ordinal_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=np.nan)\n",
    "train_df[ordinal] = ordinal_encoder.fit_transform(train_df[ordinal]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['carrier'] = test['carrier'].apply(lambda x: 'VODAFONE' if 'VODAFONE' in x else x)\n",
    "test['carrier'] = test['carrier'].apply(lambda x: 'VODAFONE' if 'VF' in x else x)\n",
    "test['carrier'] = test['carrier'].apply(lambda x: 'TURKCELL' if 'LIFECELL' in x else x)\n",
    "test['carrier'] = test['carrier'].apply(lambda x: 'TURK_TELEKOM' if 'TURK TELEKO' in x else x)\n",
    "test['carrier'] = test['carrier'].apply(lambda x: 'TURK_TELEKOM' if 'TÜRK TELEKO' in x else x)\n",
    "test['carrier'] = test['carrier'].apply(lambda x: 'TURK_TELEKOM' if 'TURKTELEKOM' in x else x)\n",
    "test['carrier'] = test['carrier'].str.replace('^KCELL ', 'AKCELL', regex=True) \n",
    "\n",
    "yurtdisi = ['ALMADAR','AIRTEL','AZERCELL','BAKCELL','O2','BEE','A1 ','3_AT','IRANCELL',\n",
    "            'AYYILDIZ','BH','NL','ORANGE','MOLDCELL','ZAIN','YETTEL','VERIZONE','TELEKOM',\n",
    "            'TELENOR','TELE2','TELIA','MAGTI','STC','BOUYGUES','HORMUUD','JIO','LIDL','KSA',\n",
    "            'FREEDOM','BUDGET','XFINITY','CHINA_TELECOM','MTN','1&1','BASE','CLARO','GEOCELL',\n",
    "            'MEGAFONE','GSMOBILE','ETISALAT','TIM','MAXIS','PROXIMUS', 'SUNRISE', 'WINDTRE', \n",
    "            'VODACOM', 'LYCAMOBILE','LIBYANA','TIGO', 'ASIACELL', 'SFR','CUBACELL','AKCELL','SALT','T-MOBILE'] \n",
    "sirket = ['TURKCELL','BIMCELL','AVEA','VODAFONE','TURK_TELEKOM','TEKNOSA','PTTCELL','KKTCELL']\n",
    "\n",
    "birlesim = yurtdisi+sirket\n",
    "\n",
    "for anahtarKelime in birlesim:\n",
    "    test['carrier'] = test['carrier'].apply(lambda x: anahtarKelime if anahtarKelime in x else x)\n",
    "    \n",
    "unknown1 = ['HAYAT','FENER','TRABZON','61','UNKNOWN',' ','nknown']\n",
    "for anahtarKelime in unknown1:\n",
    "    test['carrier'] = test['carrier'].apply(lambda x: 'UNKNOWN' if anahtarKelime in x else x)\n",
    "    \n",
    "b=test['carrier'].unique()\n",
    "\n",
    "unknown = [row for row in b if row not in birlesim]\n",
    "test['carrier'] = test['carrier'].apply(lambda x: 'UNKNOWN' if x in unknown else x if x not in unknown else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal = ['carrier', 'devicebrand'] \n",
    "ordinal_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=np.nan)\n",
    "test[ordinal] = ordinal_encoder.fit_transform(test[ordinal]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.drop(\"id\", axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.drop(\"target\", axis=1)\n",
    "y = train_df[\"target\"]\n",
    "X = X.drop([\"id\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultiOutputRegressor(estimator=GradientBoostingRegressor())</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultiOutputRegressor</label><div class=\"sk-toggleable__content\"><pre>MultiOutputRegressor(estimator=GradientBoostingRegressor())</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingRegressor</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultiOutputRegressor(estimator=GradientBoostingRegressor())"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = multioutput.MultiOutputRegressor(ensemble.GradientBoostingRegressor())\n",
    "reg.fit(X, numpy_dizi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = reg.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.24345104,  0.78853258,  0.09088579, ...,  0.31445502,\n",
       "         0.28746954,  0.24959528],\n",
       "       [ 0.32557741,  0.57686075,  0.01418683, ...,  0.10925412,\n",
       "         0.05733983,  0.25882473],\n",
       "       [ 0.12069751,  0.87852954,  0.02485349, ...,  0.04852757,\n",
       "         0.50638738,  0.12885674],\n",
       "       ...,\n",
       "       [ 0.17974986,  0.75966793,  0.11488464, ...,  0.09703592,\n",
       "        -0.00848688,  0.27685238],\n",
       "       [ 0.18230759,  0.75539181,  0.22073843, ...,  0.05101418,\n",
       "         0.39024897,  0.23389084],\n",
       "       [ 0.26847778,  0.64368436,  0.264168  , ...,  0.04970338,\n",
       "         0.00336058,  0.26756072]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_sub(ypred):\n",
    "    \n",
    "\n",
    "    sample = pd.read_csv(\"csv_sample.csv\")\n",
    "\n",
    "    submission = pd.DataFrame({\"id\": sample[\"id\"],\n",
    "                                \"target\": ypred})\n",
    "\n",
    "    # submission[\"target\"] = submission[\"target\"].astype(int)\n",
    "                                \n",
    "    submission.to_csv(\"01.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "model = joblib.load('model_dosyasi.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in y_pred:\n",
    "    list_with_index = [(value, index) for index, value in enumerate(row)]\n",
    "    sorted_list = sorted(list_with_index, key=lambda x: x[0])\n",
    "    three_values = [x[1] for x in sorted_list[-3:]]\n",
    "    row[three_values]=1\n",
    "    row[~np.isin(np.arange(len(row)), three_values)] = 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_pred.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 1, 0],\n",
       "       ...,\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [row.tolist() for row in y_pred]\n",
    "# y_pred = pd.Series(y_pred)\n",
    "\n",
    "sample_sub(pd.Series(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##################### Shape #####################\n",
      "(11955, 2)\n",
      "##################### Types #####################\n",
      "id        object\n",
      "target    object\n",
      "dtype: object\n",
      "##################### Head #####################\n",
      "                          id                       target\n",
      "0  2e6105f5911256f4f6c4813ed  [0, 1, 0, 1, 0, 1, 0, 0, 0]\n",
      "1  c56ad71dae0a5dbd3e7d36adc  [0, 1, 0, 1, 0, 1, 0, 0, 0]\n",
      "2  4d02ea175f6581f0c6385311f  [0, 1, 0, 0, 0, 1, 0, 1, 0]\n",
      "3  3412d27a86c286ba078fa935c  [0, 1, 0, 1, 0, 1, 0, 0, 0]\n",
      "4  0203b561f6f7e10eafa46eefa  [0, 1, 0, 0, 0, 1, 0, 1, 0]\n",
      "##################### Tail #####################\n",
      "                              id                       target\n",
      "11950  7687113f46112edf4f56666ee  [0, 1, 0, 1, 0, 0, 0, 0, 1]\n",
      "11951  5ff8eb7a06fd48b60dbc04f34  [0, 1, 0, 1, 0, 1, 0, 0, 0]\n",
      "11952  ac23a7b9ad3e5d61e738c854b  [0, 1, 0, 1, 0, 1, 0, 0, 0]\n",
      "11953  7da05018634ea2eee4b122756  [0, 1, 0, 1, 0, 1, 0, 0, 0]\n",
      "11954  57dbc6a230a851e6e2ee5c429  [0, 1, 0, 1, 0, 1, 0, 0, 0]\n",
      "##################### NA #####################\n",
      "id        0\n",
      "target    0\n",
      "dtype: int64\n",
      "##################### DESCRIBE #####################\n",
      "                               id                       target\n",
      "count                       11955                        11955\n",
      "unique                      11955                           11\n",
      "top     2e6105f5911256f4f6c4813ed  [0, 1, 0, 1, 0, 1, 0, 0, 0]\n",
      "freq                            1                         9927\n",
      "##################### COLUMN #####################\n",
      "id --- nunique: 11955\n",
      "\n",
      "##################### COLUMN #####################\n",
      "target --- nunique: 11 --- unique: ['[0, 1, 0, 1, 0, 1, 0, 0, 0]' '[0, 1, 0, 0, 0, 1, 0, 1, 0]'\n",
      " '[1, 1, 0, 0, 0, 1, 0, 0, 0]' '[0, 1, 0, 1, 1, 0, 0, 0, 0]'\n",
      " '[0, 1, 0, 0, 1, 1, 0, 0, 0]' '[0, 1, 0, 1, 0, 0, 0, 1, 0]'\n",
      " '[1, 1, 0, 1, 0, 0, 0, 0, 0]' '[0, 1, 0, 0, 0, 1, 0, 0, 1]'\n",
      " '[0, 1, 0, 0, 1, 0, 0, 1, 0]' '[0, 1, 0, 1, 0, 0, 0, 0, 1]'\n",
      " '[0, 0, 0, 1, 1, 1, 0, 0, 0]']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "zero = pd.read_csv('01.csv')\n",
    "utils.check_df(zero)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
